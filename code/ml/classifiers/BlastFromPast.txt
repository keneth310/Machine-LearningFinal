Authors: Brisa Salazar & Kenny Gonzalez 
1) (chardonnay
    (pinot
        (blanc
        (zinfandel
            (merlot
            predict=1.0
            predict=7.0)
            (sauvignon
            predict=10.0
            predict=15.0))
        (sauvignon
            (a
            predict=16.0
            predict=17.0)
            (young
            predict=0.0
            predict=15.0)))
        (grigio
        (gris
            (brut
            predict=2.0
            predict=6.0)
            predict=3.0)
        (valley
            predict=4.0
            predict=15.0)))
    (pinot
        (bubbles
        (brut
            (sparkling
            predict=5.0
            predict=6.0)
            predict=6.0)
        predict=6.0)
        (syrah
        (any
            (aromatics
            predict=6.0
            predict=5.0)
            predict=4.0)
        predict=2.0)))

Thoughts on the tree: We see the top node of tree is "Chardonay" from which two nodes, 
a left node with the label "blanc" and a right leaf node "zinfandel." The tree conitnues as 
such, with leaf nodes where we have the "predict" varaible, where we eventaully get to the point 
that at the bottom of the tree, there is only leaf nodes. 

2) If we predicted the majority class, the accuracy is 50.69%
3) Link to table with results: https://docs.google.com/spreadsheets/d/1BC-u4sJ3BNCI_6TRF92JSyvusw6hot_rn34h-e4Ffec/edit?usp=sharing
   There is clear evidence of overfitting in the testing data results simply because the accuracy rate is
   near 100%. The best depth to use would be 10 becuase there does't seem to be much overfitting and the 
   accuracy rate is 75% which is generally good for an ML model. 