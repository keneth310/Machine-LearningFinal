4. Here is the link to our data table: https://docs.google.com/spreadsheets/d/1IgHT9K1E2vJ0BekHfLEHwEhXtH8U0VW4QMux76t_82M/edit?usp=sharing
   Running t-tests on our data, we found that the best approach was using an AVA Decition Tree Classifier with a depth of 2. Although the 
   accuracy range for OVA and AVA remained betwen high 50's and low 60's regardless of the depth limit, AVA showed higher accuracy rates. 
   The accuray rates of AVA were significantly different from the accuracy rate of a MultiClass Decision Tree running on a depth of 2, which 
   we found to be the best depth to run on. 

5. Here are the different timings for the respective classifier: 
------------------------
OVA:
Average train time: 24.621s
Average test time: 9.0E-4s
------------------------
AVA:
Average train time: 13.1736s
Average test time: 0.0192s
------------------------

Do the timings make sense? 
We generated our results with the classifierTImer class given to us. We get that OVA is slower to train and test than AVA is to also train and test. 
We think this makes sense because in one versus all, we are comparing that one label against all other labels in the data. However, 
in AVA, we are comparing it against another label. In the case that it is not either of those two labels that we are focusing on, we ignore those cases. 
Again, given the implementation that AVA only focus on 2 labels at a time, then it makes sense that training is faster for AVA than it is for OVA. 

6. The best approach we found on this data was using an AVA Decision Tree Classifier with a depth limit of 2. It had the highest accuracy rate across the 
   different depth limits and although the difference in using AVA with a depth of 3 versus a depth limit of 2 was not significnat, AVA with a depth limit
   of 2 had the better accuracy, by a decimal value. 

7.
